{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "#device = 0\n",
    "#torch.cuda.set_device(device)\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "#%matplotlib notebook\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append('../fastai/')\n",
    "import fastai\n",
    "from fastai.vision import *\n",
    "from fastai.vision.learner import model_meta\n",
    "\n",
    "sys.path.append('../models-pytorch/pretrained-models.pytorch')\n",
    "import pretrainedmodels\n",
    "from pretrainedmodels import *\n",
    "\n",
    "from typing import Dict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models import *\n",
    "from torchsummary import summary\n",
    "from pathlib import Path\n",
    "from functools import partial, update_wrapper\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.image as mpimg\n",
    "import shutil\n",
    "\n",
    "\n",
    "PATH = Path('/home/Deep_Learner/private/network/datasets/Hypophysenadenome-Rezidive/')\n",
    "PATH_LOCAL = Path('/home/Deep_Learner/private/local/')\n",
    "WSIS_RELAPSE = PATH/'wsis_relapse'\n",
    "TILES_RELAPSE = PATH_LOCAL/'tiles_relapse'\n",
    "TILES_NON_RELAPSE = PATH_LOCAL/'tiles_non_relapse'\n",
    "\n",
    "LABELS_NAME = 'rezidive-labels.xlsx'\n",
    "LABELS = PATH/LABELS_NAME\n",
    "\n",
    "\n",
    "\n",
    "nw = 16   #number of workers for data loader\n",
    "torch.backends.cudnn.benchmark=True\n",
    "\n",
    "#def batch_stats(self, funcs:Collection[Callable]=None)->Tensor:\n",
    "#        \"Grab a batch of data and call reduction function `func` per channel\"\n",
    "#        funcs = ifnone(funcs, [torch.mean,torch.std])\n",
    "#        x = self.one_batch(ds_type=DatasetType.Train, denorm=False)[0].cpu()\n",
    "#        return [func(channel_view(x), 1) for func in funcs]\n",
    "#        \n",
    "#vision.data.ImageDataBunch.batch_stats = batch_stats\n",
    "\n",
    "sz = 512\n",
    "bs = 6\n",
    "\n",
    "#fastai defaults\n",
    "tta_beta = 0.4 \n",
    "tta_scale = 1.35\n",
    "dropout = 0.5\n",
    "wd = 0.01\n",
    "\n",
    "seed = 69\n",
    "np.random.seed(seed)\n",
    "\n",
    "num2lbs = {\n",
    "    0:\"non_relapse\", \n",
    "    1:\"relapse\"\n",
    "}\n",
    "\n",
    "lbs2num = {l:n for n,l in num2lbs.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.torch_core import flatten_model\n",
    "\n",
    "def arch_summary(arch):\n",
    "    model = arch(False)\n",
    "    tot = 0\n",
    "    for i, l in enumerate(model.children()):\n",
    "        n_layers = len(flatten_model(l))\n",
    "        tot += n_layers\n",
    "        print(f'({i}) {l.__class__.__name__:<12}: {n_layers:<4}layers (total: {tot})')\n",
    "\n",
    "def show(np):\n",
    "    return util.np_to_pil(np)\n",
    "\n",
    "Path.ls = lambda x: [p for p in list(x.iterdir()) if '.ipynb_checkpoints' not in p.name]\n",
    "\n",
    "def show_multiple_images(path, rows = 3, figsize=(128, 64)):\n",
    "    imgs = [open_image(p) for p in path.ls()]\n",
    "    show_all(imgs=imgs, r=rows, figsize=figsize)\n",
    "    \n",
    "def show_multiple_images_big(path:pathlib.Path):\n",
    "    for p in path.ls():\n",
    "        plt.imshow(mpimg.imread(str(p)))\n",
    "        plt.show()\n",
    "        \n",
    "def get_id_from_path(path):\n",
    "    path = Path(path)\n",
    "    split = path.stem.split('-')\n",
    "    return f'{split[0]}-{split[1]}'\n",
    "\n",
    "def flatten(list_of_lists):\n",
    "    result = []\n",
    "    for l in list_of_lists:\n",
    "        if len(l) == 1:\n",
    "            result.append(l[0])\n",
    "        else:\n",
    "            for elem in l:\n",
    "                result.append(elem)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/PPPW/deep-learning-random-explore/blob/master/CNN_archs/cnn_archs.ipynb\n",
    "\n",
    "def identity(x): return x\n",
    "\n",
    "def nasnetamobile(pretrained=True):\n",
    "    pretrained = 'imagenet' if pretrained else None\n",
    "    model = pretrainedmodels.nasnetamobile(pretrained=pretrained, num_classes=1000)  \n",
    "    model.logits = identity\n",
    "    model_meta[nasnetamobile] =  { 'cut': identity, 'split': lambda m: (list(m[0][0].children())[8], m[1]) }\n",
    "    return nn.Sequential(model)\n",
    "\n",
    "#arch_summary(lambda _: nasnetamobile(False)[0])\n",
    "\n",
    "def se_resnext50_32x4d(pretrained=True):\n",
    "    pretrained = 'imagenet' if pretrained else None\n",
    "    model = pretrainedmodels.se_resnext50_32x4d(pretrained=pretrained)\n",
    "    model_meta[se_resnext50_32x4d] =  {'cut': -2, 'split': lambda m: (m[0][3], m[1]) }\n",
    "    return model\n",
    "\n",
    "#arch_summary(lambda _: pretrainedmodels.se_resnext50_32x4d(pretrained=None))\n",
    "\n",
    "def se_resnext101_32x4d(pretrained=True):\n",
    "    pretrained = 'imagenet' if pretrained else None\n",
    "    model = pretrainedmodels.se_resnext101_32x4d(pretrained=pretrained)\n",
    "    model_meta[se_resnext101_32x4d] =  {'cut': -2, 'split': lambda m: (m[0][3], m[1]) }\n",
    "    return model\n",
    "\n",
    "def xception(pretrained=True):\n",
    "    pretrained = 'imagenet' if pretrained else None\n",
    "    model = pretrainedmodels.xception(pretrained=pretrained)\n",
    "    model_meta[xception] =  { 'cut': -1, 'split': lambda m: (m[0][11], m[1]) }\n",
    "    return model\n",
    "\n",
    "def inceptionv4(pretrained=True):\n",
    "    pretrained = 'imagenet' if pretrained else None\n",
    "    model = pretrainedmodels.inceptionv4(pretrained=pretrained)\n",
    "    model_meta[xception] =  { 'cut': -2, 'split': lambda m: (m[0][11], m[1]) }\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "#n='test'\n",
    "\n",
    "n = np.load('n-rez.npy')\n",
    "print(n)\n",
    "\n",
    "m = n+1\n",
    "m=4\n",
    "np.save('n-rez', m)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split dataset into train, valid and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff00ca7fa90640aaa3ea8084be7259eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=34518), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "seed: 69\n",
      "64439\n",
      "67\n",
      "6004\n",
      "13\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(LABELS).set_index('id')\n",
    "test_pct = 0\n",
    "valid_pct = 0.15\n",
    "\n",
    "###\n",
    "# RELAPSE\n",
    "###\n",
    "\n",
    "#key: patient, value: list of wsi names\n",
    "patient_to_wsi_ids_relapse = {}\n",
    "ids_relapse_all = [get_id_from_path(p) for p in (WSIS_RELAPSE.ls()) if p.suffix == '.ndpi']\n",
    "excluded_ids = []\n",
    "for id in ids_relapse_all:\n",
    "    if id not in excluded_ids:\n",
    "        patient = df.at[id, 'Patient']\n",
    "        if patient in patient_to_wsi_ids_relapse.keys():\n",
    "            patient_to_wsi_ids_relapse[patient].append(id)\n",
    "        else:\n",
    "            patient_to_wsi_ids_relapse[patient] = [id]\n",
    "if test_pct != 0:            \n",
    "    patients_relapse_train_and_valid, patients_relapse_test = train_test_split(list(patient_to_wsi_ids_relapse.keys()), \n",
    "                                                                               test_size=test_pct, \n",
    "                                                                               random_state=seed)\n",
    "    patients_relapse_train, patients_relapse_valid = train_test_split(patients_relapse_train_and_valid, \n",
    "                                                                      test_size=valid_pct, \n",
    "                                                                      random_state=seed)\n",
    "else:\n",
    "    patients_relapse_train, patients_relapse_valid = train_test_split(list(patient_to_wsi_ids_relapse.keys()), \n",
    "                                                                      test_size=valid_pct, \n",
    "                                                                      random_state=seed)\n",
    "    patients_relapse_test = []\n",
    "    \n",
    "    \n",
    "\n",
    "ids_relapse_train = flatten([patient_to_wsi_ids_relapse[pat] for pat in patients_relapse_train])\n",
    "ids_relapse_valid = flatten([patient_to_wsi_ids_relapse[pat] for pat in patients_relapse_valid])\n",
    "ids_relapse_test = flatten([patient_to_wsi_ids_relapse[pat] for pat in patients_relapse_test])\n",
    "\n",
    "tile_paths_relapse_all = [Path(f'{p.parts[-2]}/{p.parts[-1]}') for p in (TILES_RELAPSE.ls()) if p.suffix == '.png']\n",
    "tile_paths_relapse_train = [p for p in tile_paths_relapse_all if get_id_from_path(p) in ids_relapse_train]\n",
    "tile_paths_relapse_val = [p for p in tile_paths_relapse_all if get_id_from_path(p) in ids_relapse_valid]\n",
    "tile_paths_relapse_test = [p for p in tile_paths_relapse_all if get_id_from_path(p) in ids_relapse_test]\n",
    "\n",
    "\n",
    "###\n",
    "# NON RELAPSE\n",
    "###\n",
    "tile_paths_non_relapse_all = [Path(f'{p.parts[-2]}/{p.parts[-1]}') for p in (TILES_NON_RELAPSE.ls()) if p.suffix == '.png']\n",
    "\n",
    "ids_non_relapse_all = []\n",
    "for p in tqdm(tile_paths_non_relapse_all):\n",
    "    ids_non_relapse_all.append(get_id_from_path(p))\n",
    "ids_non_relapse_all = list(set(ids_non_relapse_all))\n",
    "\n",
    "if test_pct != 0:\n",
    "    ids_non_relapse_train_and_valid, ids_non_relapse_test = train_test_split(ids_non_relapse_all, \n",
    "                                                                             test_size=test_pct, \n",
    "                                                                             random_state=seed)\n",
    "    ids_non_relapse_train, ids_non_relapse_val = train_test_split(ids_non_relapse_train_and_valid, \n",
    "                                                                  test_size=valid_pct, \n",
    "                                                                  random_state=seed)\n",
    "else:\n",
    "    ids_non_relapse_train, ids_non_relapse_val = train_test_split(ids_non_relapse_all, \n",
    "                                                                  test_size=valid_pct, \n",
    "                                                                  random_state=seed)\n",
    "    ids_non_relapse_test = []\n",
    "    \n",
    "\n",
    "tile_paths_non_relapse_train = [p for p in tile_paths_non_relapse_all if get_id_from_path(p) in ids_non_relapse_train]\n",
    "tile_paths_non_relapse_val = [p for p in tile_paths_non_relapse_all if get_id_from_path(p) in ids_non_relapse_val]\n",
    "tile_paths_non_relapse_test = [p for p in tile_paths_non_relapse_all if get_id_from_path(p) in ids_non_relapse_test]\n",
    "\n",
    "###\n",
    "# COMBINE\n",
    "###\n",
    "tile_paths_train = tile_paths_non_relapse_train + tile_paths_relapse_train\n",
    "tile_paths_val = tile_paths_non_relapse_val + tile_paths_relapse_val\n",
    "tile_paths_test = tile_paths_non_relapse_test + tile_paths_relapse_test\n",
    "\n",
    "df_tile_paths_train_and_valid = pd.DataFrame((tile_paths_train+tile_paths_val), columns=['name'])\n",
    "\n",
    "print(f'seed: {seed}')\n",
    "print(len(tile_paths_train))\n",
    "print(len(set([get_id_from_path(p) for p in tile_paths_train])))\n",
    "print(len(tile_paths_val))\n",
    "print(len(set([get_id_from_path(p) for p in tile_paths_val])))\n",
    "print(len(tile_paths_test))\n",
    "print(len(set([get_id_from_path(p) for p in tile_paths_test])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = get_transforms(flip_vert=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfms = ([RandTransform(tfm=TfmAffine (dihedral_affine), kwargs={}, p=1.0, resolved={}, do_run=True, is_random=True),\n",
    "#        RandTransform(tfm=TfmLighting (brightness), kwargs={'change': (0.475, 0.525)}, p=0.75, resolved={}, do_run=True, is_random=True),\n",
    "#        RandTransform(tfm=TfmLighting (contrast), kwargs={'scale': (0.95, 1.0526315789473684)}, p=0.75, resolved={}, do_run=True, is_random=True)],\n",
    "#        [])\n",
    "\n",
    "#def get_ex(): return open_image(str(TRAIN.ls()[0]))\n",
    "#\n",
    "#def plots_f(rows, cols, width, height, **kwargs):\n",
    "#    [get_ex().apply_tfms(tfms[0], **kwargs).show(ax=ax) for i,ax in enumerate(plt.subplots(\n",
    "#        rows,cols,figsize=(width,height))[1].flatten())]\n",
    "#\n",
    "#plots_f(2, 4, 12, 6, size=224)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datablock API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_func(path):\n",
    "    path = Path(path)\n",
    "    id = get_id_from_path(path)\n",
    "    if id in ids_non_relapse_all:\n",
    "        return [lbs2num['non_relapse']]\n",
    "    else:\n",
    "        return [lbs2num['relapse']]\n",
    "\n",
    "    \n",
    "def split_func(path):\n",
    "    path = Path(path)\n",
    "    return get_id_from_path(path) in (ids_non_relapse_val+ids_relapse_valid) \n",
    "\n",
    "#data = ImageList.from_folder(path=TRAIN, extensions=['.png'])\n",
    "data = ImageList.from_df(df_tile_paths_train_and_valid, path=PATH_LOCAL)\n",
    "data = data.split_by_valid_func(split_func)\n",
    "data = data.label_from_func(label_func)\n",
    "data = data.transform(tfms=tfms, size=sz)\n",
    "#data = data.add_test_folder(test_folder=TEST_EXPERIMENTING)\n",
    "if test_pct != 0:\n",
    "    data = data.add_test([PATH/p for p in tile_paths_test])\n",
    "data = data.databunch(bs=bs, num_workers=nw, path=PATH/f'{n}-currently-training')\n",
    "data = data.normalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_frozen = 5\n",
    "epochs_unfrozen = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth\" to /home/Deep_Learner/.cache/torch/checkpoints/resnext101_32x8d-8ba56ff5.pth\n",
      "100%|██████████| 340M/340M [00:31<00:00, 11.4MB/s] \n"
     ]
    }
   ],
   "source": [
    "arch = resnext101_32x8d\n",
    "learner = cnn_learner(data=data, \n",
    "                     base_arch=arch, \n",
    "                     metrics=[accuracy_thresh], \n",
    "                     ps=dropout, \n",
    "                     pretrained=True, \n",
    "                     wd = wd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4-resnext101_32x8d-size512-bs6-epochs_head5-epochs_complete10-seed_69-test_pct_0-valid_pct_0.15'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nameBase = f'{n}-{arch.__name__}-size{sz}-bs{bs}-epochs_head{epochs_frozen}-epochs_complete{epochs_unfrozen}-seed_{seed}-test_pct_{test_pct}-valid_pct_{valid_pct}'\n",
    "nameBase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.lr_find()\n",
    "learner.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 4e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy_thresh</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.369602</td>\n",
       "      <td>0.323050</td>\n",
       "      <td>0.868236</td>\n",
       "      <td>1:18:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.293107</td>\n",
       "      <td>0.344109</td>\n",
       "      <td>0.854292</td>\n",
       "      <td>1:19:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.202350</td>\n",
       "      <td>0.331438</td>\n",
       "      <td>0.867788</td>\n",
       "      <td>1:19:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.135799</td>\n",
       "      <td>0.298974</td>\n",
       "      <td>0.886082</td>\n",
       "      <td>1:19:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.203151</td>\n",
       "      <td>0.373304</td>\n",
       "      <td>0.841819</td>\n",
       "      <td>1:19:30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.fit_one_cycle(cyc_len=epochs_frozen, max_lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nameHead = f'{nameBase}-head'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learner.save(nameHead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Learner(data=ImageDataBunch;\n",
       "\n",
       "Train: LabelList (64439 items)\n",
       "x: ImageList\n",
       "Image (3, 512, 512),Image (3, 512, 512),Image (3, 512, 512),Image (3, 512, 512),Image (3, 512, 512)\n",
       "y: MultiCategoryList\n",
       "0,0,0,0,0\n",
       "Path: /home/Deep_Learner/private/local;\n",
       "\n",
       "Valid: LabelList (6004 items)\n",
       "x: ImageList\n",
       "Image (3, 512, 512),Image (3, 512, 512),Image (3, 512, 512),Image (3, 512, 512),Image (3, 512, 512)\n",
       "y: MultiCategoryList\n",
       "0,0,0,0,0\n",
       "Path: /home/Deep_Learner/private/local;\n",
       "\n",
       "Test: None, model=Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (6): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (7): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (8): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (9): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (10): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (11): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (12): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (13): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (14): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (15): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (16): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (17): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (18): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (19): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (20): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (21): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (22): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): AdaptiveConcatPool2d(\n",
       "      (ap): AdaptiveAvgPool2d(output_size=1)\n",
       "      (mp): AdaptiveMaxPool2d(output_size=1)\n",
       "    )\n",
       "    (1): Flatten()\n",
       "    (2): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.25, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=512, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.5, inplace=False)\n",
       "    (8): Linear(in_features=512, out_features=2, bias=True)\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of BCEWithLogitsLoss(), metrics=[<function accuracy_thresh at 0x7f26709b9378>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/home/Deep_Learner/private/network/datasets/Hypophysenadenome-Rezidive/4-currently-training'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[], layer_groups=[Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace=True)\n",
       "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (4): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "  (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (8): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (10): ReLU(inplace=True)\n",
       "  (11): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (13): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (14): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (15): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "  (16): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (17): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (19): ReLU(inplace=True)\n",
       "  (20): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (22): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "  (23): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (24): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (25): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (26): ReLU(inplace=True)\n",
       "  (27): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (29): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "  (30): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (31): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (32): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (33): ReLU(inplace=True)\n",
       "  (34): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "  (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (36): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (38): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "  (39): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (40): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (42): ReLU(inplace=True)\n",
       "  (43): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (44): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (45): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "  (46): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (47): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (48): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (49): ReLU(inplace=True)\n",
       "  (50): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (51): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (52): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "  (53): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (54): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (55): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (56): ReLU(inplace=True)\n",
       "  (57): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (58): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (59): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "  (60): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (61): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (62): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (63): ReLU(inplace=True)\n",
       "  (64): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "  (65): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (66): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (67): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (68): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "  (69): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (70): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (71): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (72): ReLU(inplace=True)\n",
       "  (73): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (74): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (75): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "  (76): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (77): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (78): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (79): ReLU(inplace=True)\n",
       "  (80): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (81): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (82): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "  (83): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (84): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (85): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (86): ReLU(inplace=True)\n",
       "  (87): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (88): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (89): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "  (90): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (91): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (92): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (93): ReLU(inplace=True)\n",
       "  (94): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (95): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (96): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "  (97): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (98): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (99): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (100): ReLU(inplace=True)\n",
       "  (101): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (102): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (103): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "  (104): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (105): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (106): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (107): ReLU(inplace=True)\n",
       "  (108): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (109): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (110): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "  (111): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (112): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (113): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (114): ReLU(inplace=True)\n",
       "  (115): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (116): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (117): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "  (118): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (119): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (120): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (121): ReLU(inplace=True)\n",
       "  (122): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (123): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (124): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "  (125): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (126): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (127): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (128): ReLU(inplace=True)\n",
       "  (129): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (130): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (131): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "  (132): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (133): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (134): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (135): ReLU(inplace=True)\n",
       "  (136): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (137): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (138): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "  (139): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (140): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (141): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (142): ReLU(inplace=True)\n",
       "  (143): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (144): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (145): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "  (146): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (147): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (148): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (149): ReLU(inplace=True)\n",
       "  (150): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (151): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (152): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "  (153): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (154): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (155): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (156): ReLU(inplace=True)\n",
       "  (157): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (158): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (159): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "  (160): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (161): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (162): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (163): ReLU(inplace=True)\n",
       "  (164): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (165): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (166): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "  (167): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (168): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (169): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (170): ReLU(inplace=True)\n",
       "  (171): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (172): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (173): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "  (174): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (175): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (176): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (177): ReLU(inplace=True)\n",
       "  (178): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (179): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (180): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "  (181): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (182): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (183): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (184): ReLU(inplace=True)\n",
       "  (185): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (186): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (187): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "  (188): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (189): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (190): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (191): ReLU(inplace=True)\n",
       "  (192): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (193): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (194): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "  (195): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (196): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (197): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (198): ReLU(inplace=True)\n",
       "  (199): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (200): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (201): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "  (202): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (203): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (204): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (205): ReLU(inplace=True)\n",
       "  (206): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (207): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (208): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "  (209): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (210): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (211): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (212): ReLU(inplace=True)\n",
       "  (213): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (214): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (215): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "  (216): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (217): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (218): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (219): ReLU(inplace=True)\n",
       "  (220): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (221): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (222): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "  (223): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (224): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (225): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (226): ReLU(inplace=True)\n",
       "  (227): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "  (228): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (229): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (230): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (231): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "  (232): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (233): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (234): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (235): ReLU(inplace=True)\n",
       "  (236): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (237): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (238): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "  (239): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (240): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (241): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (242): ReLU(inplace=True)\n",
       "), Sequential(\n",
       "  (0): AdaptiveAvgPool2d(output_size=1)\n",
       "  (1): AdaptiveMaxPool2d(output_size=1)\n",
       "  (2): Flatten()\n",
       "  (3): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (4): Dropout(p=0.25, inplace=False)\n",
       "  (5): Linear(in_features=4096, out_features=512, bias=True)\n",
       "  (6): ReLU(inplace=True)\n",
       "  (7): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (8): Dropout(p=0.5, inplace=False)\n",
       "  (9): Linear(in_features=512, out_features=2, bias=True)\n",
       ")], add_time=True, silent=False, cb_fns_registered=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.load('bestmodel_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.lr_find(start_lr=1e-10, end_lr=10, num_it=1000)\n",
    "learner.recorder.plot(skip_start=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2 = 1e-7\n",
    "lr3 = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.callbacks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded bestmodel_2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='7', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      14.29% [1/7 1:58:43<11:52:22]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy_thresh</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.145521</td>\n",
       "      <td>0.308344</td>\n",
       "      <td>0.887408</td>\n",
       "      <td>1:58:43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='6165' class='' max='10739', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      57.41% [6165/10739 1:06:35<49:24 0.1015]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.fit_one_cycle(cyc_len=epochs_unfrozen, \n",
    "                      max_lr=slice(lr2, lr3), \n",
    "                      callbacks=[SaveModelCallback(learner, every='epoch', monitor='accuracy_thresh')], \n",
    "                      start_epoch=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learner.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.recorder.plot_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nameComplete = f'{nameBase}-complete'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save(nameComplete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learner.load(nameComplete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction per case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(predicted_classes:list, all_classes:list):\n",
    "    for c in predicted_classes:\n",
    "        assert c in all_classes\n",
    "    n = len(all_classes)\n",
    "    res = np.zeros(n, int)\n",
    "    for i, c in enumerate(all_classes):\n",
    "        if c in predicted_classes:\n",
    "            res[i] = 1 \n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "def ensemble_predict(dict_arch_to_path_of_saved_model:typing.Dict[Callable, pathlib.Path], \n",
    "                     data:fastai.vision.data.ImageDataBunch,\n",
    "                     ds_type:fastai.basic_data.DatasetType,\n",
    "                     tta:bool, \n",
    "                     scale:float,\n",
    "                     beta:float):\n",
    "    \"\"\"\n",
    "    tta: Should test time augmentation be used?\n",
    "    scale: if tta is True -> scaling factor for tta\n",
    "    beta: if tta is True -> beta factor for tta\n",
    "    check this out for more infos: https://docs.fast.ai/basic_train.html#Test-time-augmentation\n",
    "    \"\"\"\n",
    "   \n",
    "    print(f'{str([a.__name__ for a in dict_arch_to_path_of_saved_model.keys()])}_sz{sz}_ensembled')\n",
    "    \n",
    "    predsList = []\n",
    "    for arch in dict_arch_to_path_of_saved_model.keys():\n",
    "        learner = cnn_learner(data=data, base_arch=arch, pretrained=False)\n",
    "        learner.load(dict_arch_to_path_of_saved_model[arch])\n",
    "        if tta is True:\n",
    "            preds = learner.TTA(beta=beta, scale=scale, ds_type=ds_type)\n",
    "        else:\n",
    "            preds = learner.get_preds(ds_type=ds_type)\n",
    "            \n",
    "        predsList.append(preds)\n",
    "    \n",
    "    preds_ensembled = predsList[0]\n",
    "    for n, _ in enumerate(predsList):\n",
    "        if n == 0:\n",
    "            continue\n",
    "        else:\n",
    "            preds_ensembled[0] = preds_ensembled[0] + predsList[n][0]\n",
    "    preds_ensembled[0] = preds_ensembled[0]/len(predsList)\n",
    "    \n",
    "    return preds_ensembled\n",
    "\n",
    "def from_preds_to_dict_path_to_preds(preds, \n",
    "                                     imageDataBunch:fastai.vision.ImageDataBunch, \n",
    "                                     ds_type:fastai.basic_data.DatasetType,\n",
    "                                     threshold:float):\n",
    "    \"\"\"\n",
    "    preds: What fastai.vision.learner.get_preds or fastai.vision.learner.TTA return.\n",
    "            two tensors: 1st: lists with raw predictions for each class of an image\n",
    "                         2nd: lists with y_true\n",
    "            form e.g. [tensor([[0.9672, 0.9211, 0.4560, 0.8185], \n",
    "                                [0.9498, 0.8600, 0.5852, 0.7206]]),\n",
    "                         tensor([[0., 0., 0., 1.],\n",
    "                                [0., 0., 1., 1.]])]\n",
    "                                \n",
    "    RETURN:\n",
    "        key:path, value:tuple (fastai.core.MultiCategory, tensor preds one hot encoded, tensor with pure preds) \n",
    "        e.g. (MultiCategory 0, tensor([1., 0., 0., 0.]), tensor([0.9952, 0.0015, 0.0021, 0.0029]))\n",
    "    path_to_pred = {}\n",
    "    \"\"\"\n",
    "    #key:path, value:tuple (fastai.core.MultiCategory, tensor preds one hot encoded, tensor with pure preds) \n",
    "    #e.g. (MultiCategory 0, tensor([1., 0., 0., 0.]), tensor([0.9952, 0.0015, 0.0021, 0.0029]))\n",
    "    path_to_pred = {}\n",
    "    d = None\n",
    "    if ds_type is DatasetType.Valid:\n",
    "        d = imageDataBunch.valid_ds\n",
    "    elif ds_type is DatasetType.Test:\n",
    "        d = imageDataBunch.test_ds\n",
    "    elif ds_type is DatasetType.Train:\n",
    "        d = imageDataBunch.train_ds\n",
    "    for path, pred in tqdm(zip(d.items, preds[0]), total = len(d.items)):\n",
    "        multi_c = None\n",
    "        pred_one_hot_encoded = (pred > threshold).float()\n",
    "        pred_raw = pred\n",
    "        path_to_pred[path] = multi_c, pred_one_hot_encoded, pred_raw\n",
    "        \n",
    "    return path_to_pred\n",
    "\n",
    "\n",
    "def get_class_occurence_per_id(learner:fastai.vision.learner=None,\n",
    "                               labelList:fastai.data_block.LabelList=None,\n",
    "                               dict_arch_to_path_of_saved_model:typing.Dict[Callable, pathlib.Path]=None,\n",
    "                               imageDataBunch:fastai.vision.data.ImageDataBunch=None,\n",
    "                               ds_type:fastai.basic_data.DatasetType=None,\n",
    "                               tta:bool=False,                                          \n",
    "                               threshold = 0.5,                              \n",
    "                               scale:float = 1.35,\n",
    "                               beta: float = 0.4):\n",
    "    \"\"\"\n",
    "    Option 1: Hand over a fastai.vision.learner and fastai.data_block.LabelList. No tta and no ensembling available\n",
    "                for this option.\n",
    "    Option 2: Hand over a fastai.vision.learner that was initalized with a fastai.vision.data.ImageDataBunch object.\n",
    "    Option 3: Hand over dict where the keys are functions to create a model (e.g. torchvision.models.resnet50)\n",
    "                and the values are paths to saved weights. Do this to use ensembling.\n",
    "    \n",
    "    Params:\n",
    "        threshold:  threshold to consider the predictions to be correct or not\n",
    "        scale: only needed when tta is True; scale value for fastai's fastai.basic_train.Learner.TTA function\n",
    "        beta: only needed when tta is True; beta value for fastai's fastai.basic_train.Learner.TTA function\n",
    "    \"\"\"\n",
    "    \n",
    "    if labelList is not None and ds_type is not None:\n",
    "        raise ValueError('One of dataset or ds_type must be None')\n",
    "    if labelList is not None and tta is True:\n",
    "        raise ValueError('TTA is not available for a custom LabelList')\n",
    "                \n",
    "    #key:path, value:tuple (fastai.core.MultiCategory, tensor preds one hot encoded, tensor with pure preds) \n",
    "    #e.g. (MultiCategory 0, tensor([1., 0., 0., 0.]), tensor([0.9952, 0.0015, 0.0021, 0.0029]))\n",
    "    path_to_pred = {}\n",
    "    \n",
    "    #Option 1\n",
    "    if learner is not None and labelList is not None:\n",
    "        for n, path in tqdm(enumerate(labelList.items), total=len(labelList.items)):\n",
    "            pred = learner.predict(labelList[n][0], thresh=threshold)\n",
    "            path_to_pred[path] = pred\n",
    "    \n",
    "    #Option 2\n",
    "    elif learner is not None and labelList is None and  not dict_arch_to_path_of_saved_model and imageDataBunch is None:\n",
    "        if tta is True:\n",
    "            preds = learner.TTA(beta=beta, scale=scale, ds_type=ds_type)\n",
    "        else:\n",
    "            preds = learner.get_preds(ds_type=ds_type)\n",
    "        path_to_pred = from_preds_to_dict_path_to_preds(preds, learner.data, ds_type, threshold)\n",
    "                \n",
    "    #Option 3\n",
    "    elif dict_arch_to_path_of_saved_model and imageDataBunch is not None:\n",
    "        preds = ensemble_predict(dict_arch_to_path_of_saved_model, imageDataBunch, ds_type, tta, scale, beta)\n",
    "        path_to_pred = from_preds_to_dict_path_to_preds(preds, imageDataBunch, ds_type, threshold)                \n",
    "               \n",
    "    #key: id of a case; value: list with this syntax  \n",
    "    #[<number of tiles>, \n",
    "    #[<number of occurence of class1 over all tiles per id>, \n",
    "    #<number of occurence of class2 over all tiles per id>, ..., \n",
    "    #<number of occurence of classN over all tiles per id>],\n",
    "    #y_true]\n",
    "    class_occurence_per_id = {}\n",
    "    \n",
    "    for path, pred in path_to_pred.items():   \n",
    "        id = get_id_from_path(path)\n",
    "        if id in class_occurence_per_id:\n",
    "            v = class_occurence_per_id[id]\n",
    "            v[0] = v[0] + 1\n",
    "            v[1] = v[1] + pred[1]\n",
    "            class_occurence_per_id[id] = v\n",
    "        else:\n",
    "            class_occurence_per_id[id] = [1, pred[1], one_hot_encode(label_func(path), lbs2num.values())]\n",
    "            \n",
    "    return class_occurence_per_id\n",
    "\n",
    "\n",
    "def get_preds_threshold_per_id(thresholds_per_class:list, class_occurence_per_id:dict):\n",
    "    #key: id of a case; \n",
    "    #value: list with this syntax  \n",
    "    #[y_pred_th e.g. [True,False,False,False], \n",
    "    #y_true e.g. [1,0,0,0]]\n",
    "    result = {}\n",
    "    for k in class_occurence_per_id.keys():\n",
    "        y_pred_th = []\n",
    "        for n, i in enumerate(class_occurence_per_id[k][1]):\n",
    "            i = int(i)\n",
    "            y_pred_th.append(i/class_occurence_per_id[k][0] > thresholds_per_class[n])\n",
    "    \n",
    "        result[k] = [y_pred_th, class_occurence_per_id[k][2]]\n",
    "    return result\n",
    "\n",
    "def get_accuracy_over_all_ids(number_of_ids, preds_threshold_per_id:dict, per_class:bool = True, number_of_classes = len(lbs2num)):\n",
    "    if per_class is True:\n",
    "        correctly_predicted = np.zeros(number_of_classes, dtype=np.int)\n",
    "    else:\n",
    "        correctly_predicted = 0\n",
    "    for k in preds_threshold_per_id.keys():\n",
    "        pred = preds_threshold_per_id[k][0]\n",
    "        true = preds_threshold_per_id[k][1]\n",
    "        for i in range(number_of_classes):\n",
    "            if true[i] == pred[i]:\n",
    "                if per_class is True:\n",
    "                    correctly_predicted[i] = correctly_predicted[i] + 1\n",
    "                else:\n",
    "                    correctly_predicted = correctly_predicted + 1\n",
    "    if per_class is True:                    \n",
    "        correctly_predicted_percentage = {}\n",
    "        for lb, num in zip(lbs2num.keys(), correctly_predicted):\n",
    "            correctly_predicted_percentage[lb] = num/number_of_ids\n",
    "    if per_class is False:\n",
    "        correctly_predicted_percentage = correctly_predicted/number_of_ids\n",
    "\n",
    "    return correctly_predicted_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#arches = {resnext101_32x8d:Path(MODEL_PATH/'6-resnext101_32x8d-size512-bs8-seed_73/bestmodel_15'),\n",
    "         # se_resnext101_32x4d:MODEL_PATH/'11-se_resnext101_32x4d-size512-bs10-epochs_head5-epochs_complete5-seed_73/11-se_resnext101_32x4d-size512-bs8-epochs_head5-epochs_complete5-seed_73-complete'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ths = [0.5,0.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copi_val = get_class_occurence_per_id(dict_arch_to_path_of_saved_model=arches,\n",
    "#                                      imageDataBunch=data,\n",
    "#                                      ds_type=DatasetType.Valid)\n",
    "copi_val = get_class_occurence_per_id(learner=learner, ds_type=DatasetType.Valid)\n",
    "preds_th_val = get_preds_threshold_per_id(ths, copi_val)\n",
    "accuracy_per_class_val = get_accuracy_over_all_ids(len(preds_th_val), preds_th_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copi_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_th_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_per_class_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copi_test = get_class_occurence_per_id(dict_arch_to_path_of_saved_model=arches,\n",
    "#                                      imageDataBunch=data,\n",
    "#                                      ds_type=DatasetType.Test)\n",
    "copi_test = get_class_occurence_per_id(learner=learner, ds_type=DatasetType.Test)\n",
    "preds_th_test = get_preds_threshold_per_id(ths, copi_test)\n",
    "accuracy_per_class_test = get_accuracy_over_all_ids(len(preds_th_test), preds_th_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_per_class_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def custom_confusion_matrix(self, slice_size:int=1):\n",
    "        \"Confusion matrix as an `np.ndarray`.\"\n",
    "        x=torch.arange(0,self.data.c)\n",
    "        if slice_size is None: cm = ((self.pred_class==x[:,None]) & (self.y_true==x[:,None,None])).sum(2)\n",
    "        else:\n",
    "            cm = torch.zeros(self.data.c, self.data.c, dtype=x.dtype)\n",
    "            for i in range(0, self.y_true.shape[0], slice_size):\n",
    "                #cm_slice = ((self.pred_class[i:i+slice_size]==x[:,None])\n",
    "                            #& (self.y_true[i:i+slice_size]==x[:,None,None])).sum(2)\n",
    "                cm_slice = ((self.pred_class[i:i+slice_size]==x[:,None])\n",
    "                            & (self.y_true[i:i+slice_size]==(x[:,None,None]).float())).sum(2)\n",
    "                torch.add(cm, cm_slice, out=cm)\n",
    "        return to_np(cm)\n",
    "    \n",
    "fastai.train.ClassificationInterpretation.confusion_matrix = custom_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "interp.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "interp.plot_top_losses(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Validation Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "preds,y=learner.TTA(ds_type=DatasetType.Valid, scale=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## AUC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pred_score_tta_1=auc_score_1(preds,y)\n",
    "pred_score_tta_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pred_score_tta_2=auc_score_2(preds,y)\n",
    "pred_score_tta_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## ROC curve and AUC on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds, roc_auc = roc_curve_custom(preds, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "plt.xlim([-0.01, 1.0])\n",
    "plt.ylim([0.0, 1.01])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Finding threshold on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import scipy.optimize as opt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pred = preds[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pred_tensor = pred\n",
    "y_tensor = y\n",
    "\n",
    "pred = np.asarray(pred)\n",
    "y = np.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def sigmoid_np(x):\n",
    "    return 1.0/(1.0 + np.exp(-x))\n",
    "\n",
    "def F1_soft(preds,targs,th=0.,d=25.0):\n",
    "    preds = sigmoid_np(d*(preds - th))\n",
    "    targs = targs.astype(np.float)\n",
    "    score = 2.0*(preds*targs).sum(axis=0)/((preds+targs).sum(axis=0) + 1e-6)\n",
    "    return score\n",
    "\n",
    "def fit_val(x,y):\n",
    "    params = np.zeros(1)\n",
    "    wd = 1e-5\n",
    "    error = lambda p: np.concatenate((F1_soft(x,y,p) - 1.0,\n",
    "                                      wd*p), axis=None)\n",
    "    p, success = opt.leastsq(error, params)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "th = fit_val(pred, y)\n",
    "print('Thresholds: ',th)\n",
    "print('F1 macro: ', sklearn.metrics.f1_score(y, pred>th, average='macro'))\n",
    "print('F1 macro (th = 0.0): ', sklearn.metrics.f1_score(y, pred>0.0, average='macro'))\n",
    "print('F1 micro: ', sklearn.metrics.f1_score(y, pred>th, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "th, score, cv = 0,0,10\n",
    "for i in range(cv):\n",
    "    xt,xv,yt,yv = train_test_split(pred,y,test_size=0.5,random_state=i)\n",
    "    th_i = fit_val(xt,yt)\n",
    "    th += th_i\n",
    "    score +=  sklearn.metrics.f1_score(yv, xv>th_i, average='macro')\n",
    "th/=cv\n",
    "score/=cv\n",
    "print('Thresholds: ',th)\n",
    "print('F1 macro avr:',score)\n",
    "print('F1 macro: ', sklearn.metrics.f1_score(y, pred>th, average='macro'))\n",
    "print('F1 micro: ', sklearn.metrics.f1_score(y, pred>th, average='micro'))\n",
    "\n",
    "\n",
    "print('Fractions: ',(pred > th).mean(axis=0))\n",
    "print('Fractions (true): ',(y > 0.5).mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "f1 =  sklearn.metrics.f1_score(y, pred>th, average=None)\n",
    "bins = np.linspace(pred[:].min(), pred[:].max(), 50)\n",
    "plt.hist(pred[y[:] == 0][:], bins, alpha=0.5, log=True, label='false')\n",
    "plt.hist(pred[y[:] == 1][:], bins, alpha=0.5, log=True, label='true')\n",
    "plt.legend(loc='upper right')\n",
    "plt.axvline(x=th[0], color='k', linestyle='--')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLM Py3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "293px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

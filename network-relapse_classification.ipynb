{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "#device = 0\n",
    "#torch.cuda.set_device(device)\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "#%matplotlib notebook\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append('../fastai/')\n",
    "import fastai\n",
    "from fastai.vision import *\n",
    "from fastai.vision.learner import model_meta\n",
    "\n",
    "sys.path.append('../models-pytorch/pretrained-models.pytorch')\n",
    "import pretrainedmodels\n",
    "from pretrainedmodels import *\n",
    "\n",
    "from typing import Dict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models import *\n",
    "from torchsummary import summary\n",
    "from pathlib import Path\n",
    "from functools import partial, update_wrapper\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.image as mpimg\n",
    "import shutil\n",
    "\n",
    "\n",
    "PATH = Path('/home/Deep_Learner/private/network/datasets/Hypophysenadenome-Rezidive/')\n",
    "PATH_LOCAL = Path('/home/Deep_Learner/private/local/')\n",
    "WSIS_RELAPSE = PATH/'wsis_relapse'\n",
    "TILES_RELAPSE = PATH/'tiles_relapse'\n",
    "TILES_NON_RELAPSE = PATH/'tiles_non_relapse'\n",
    "\n",
    "LABELS_NAME = 'rezidive-labels.xlsx'\n",
    "LABELS = PATH/LABELS_NAME\n",
    "\n",
    "\n",
    "\n",
    "nw = 16   #number of workers for data loader\n",
    "torch.backends.cudnn.benchmark=True\n",
    "\n",
    "#def batch_stats(self, funcs:Collection[Callable]=None)->Tensor:\n",
    "#        \"Grab a batch of data and call reduction function `func` per channel\"\n",
    "#        funcs = ifnone(funcs, [torch.mean,torch.std])\n",
    "#        x = self.one_batch(ds_type=DatasetType.Train, denorm=False)[0].cpu()\n",
    "#        return [func(channel_view(x), 1) for func in funcs]\n",
    "#        \n",
    "#vision.data.ImageDataBunch.batch_stats = batch_stats\n",
    "\n",
    "sz = 512\n",
    "bs = 6\n",
    "\n",
    "#fastai defaults\n",
    "tta_beta = 0.4 \n",
    "tta_scale = 1.35\n",
    "dropout = 0.5\n",
    "wd = 0.01\n",
    "\n",
    "seed = 23\n",
    "np.random.seed(seed)\n",
    "\n",
    "num2lbs = {\n",
    "    0:\"non_relapse\", \n",
    "    1:\"relapse\"\n",
    "}\n",
    "\n",
    "lbs2num = {l:n for n,l in num2lbs.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.torch_core import flatten_model\n",
    "\n",
    "def arch_summary(arch):\n",
    "    model = arch(False)\n",
    "    tot = 0\n",
    "    for i, l in enumerate(model.children()):\n",
    "        n_layers = len(flatten_model(l))\n",
    "        tot += n_layers\n",
    "        print(f'({i}) {l.__class__.__name__:<12}: {n_layers:<4}layers (total: {tot})')\n",
    "\n",
    "def show(np):\n",
    "    return util.np_to_pil(np)\n",
    "\n",
    "Path.ls = lambda x: [p for p in list(x.iterdir()) if '.ipynb_checkpoints' not in p.name]\n",
    "\n",
    "def show_multiple_images(path, rows = 3, figsize=(128, 64)):\n",
    "    imgs = [open_image(p) for p in path.ls()]\n",
    "    show_all(imgs=imgs, r=rows, figsize=figsize)\n",
    "    \n",
    "def show_multiple_images_big(path:pathlib.Path):\n",
    "    for p in path.ls():\n",
    "        plt.imshow(mpimg.imread(str(p)))\n",
    "        plt.show()\n",
    "        \n",
    "def get_id_from_path(path):\n",
    "    path = Path(path)\n",
    "    split = path.stem.split('-')\n",
    "    return f'{split[0]}-{split[1]}'\n",
    "\n",
    "def flatten(list_of_lists):\n",
    "    result = []\n",
    "    for l in list_of_lists:\n",
    "        if len(l) == 1:\n",
    "            result.append(l[0])\n",
    "        else:\n",
    "            for elem in l:\n",
    "                result.append(elem)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/PPPW/deep-learning-random-explore/blob/master/CNN_archs/cnn_archs.ipynb\n",
    "\n",
    "def identity(x): return x\n",
    "\n",
    "def nasnetamobile(pretrained=True):\n",
    "    pretrained = 'imagenet' if pretrained else None\n",
    "    model = pretrainedmodels.nasnetamobile(pretrained=pretrained, num_classes=1000)  \n",
    "    model.logits = identity\n",
    "    model_meta[nasnetamobile] =  { 'cut': identity, 'split': lambda m: (list(m[0][0].children())[8], m[1]) }\n",
    "    return nn.Sequential(model)\n",
    "\n",
    "#arch_summary(lambda _: nasnetamobile(False)[0])\n",
    "\n",
    "def se_resnext50_32x4d(pretrained=True):\n",
    "    pretrained = 'imagenet' if pretrained else None\n",
    "    model = pretrainedmodels.se_resnext50_32x4d(pretrained=pretrained)\n",
    "    model_meta[se_resnext50_32x4d] =  {'cut': -2, 'split': lambda m: (m[0][3], m[1]) }\n",
    "    return model\n",
    "\n",
    "#arch_summary(lambda _: pretrainedmodels.se_resnext50_32x4d(pretrained=None))\n",
    "\n",
    "def se_resnext101_32x4d(pretrained=True):\n",
    "    pretrained = 'imagenet' if pretrained else None\n",
    "    model = pretrainedmodels.se_resnext101_32x4d(pretrained=pretrained)\n",
    "    model_meta[se_resnext101_32x4d] =  {'cut': -2, 'split': lambda m: (m[0][3], m[1]) }\n",
    "    return model\n",
    "\n",
    "def xception(pretrained=True):\n",
    "    pretrained = 'imagenet' if pretrained else None\n",
    "    model = pretrainedmodels.xception(pretrained=pretrained)\n",
    "    model_meta[xception] =  { 'cut': -1, 'split': lambda m: (m[0][11], m[1]) }\n",
    "    return model\n",
    "\n",
    "def inceptionv4(pretrained=True):\n",
    "    pretrained = 'imagenet' if pretrained else None\n",
    "    model = pretrainedmodels.inceptionv4(pretrained=pretrained)\n",
    "    model_meta[xception] =  { 'cut': -2, 'split': lambda m: (m[0][11], m[1]) }\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "#n='test'\n",
    "\n",
    "n = np.load('n-rez.npy')\n",
    "print(n)\n",
    "\n",
    "m = n+1\n",
    "m=3\n",
    "np.save('n-rez', m)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split dataset into train, valid and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c6514905e4044b9873b1a1898df15d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=34518), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "seed: 23\n",
      "59056\n",
      "10938\n",
      "449\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(LABELS).set_index('id')\n",
    "test_pct = 0.00000001\n",
    "valid_pct = 0.1\n",
    "\n",
    "###\n",
    "# RELAPSE\n",
    "###\n",
    "\n",
    "#key: patient, value: list of wsi names\n",
    "patient_to_wsi_ids_relapse = {}\n",
    "ids_relapse_all = [get_id_from_path(p) for p in (WSIS_RELAPSE.ls()) if p.suffix == '.ndpi']\n",
    "excluded_ids = []\n",
    "for id in ids_relapse_all:\n",
    "    if id not in excluded_ids:\n",
    "        patient = df.at[id, 'Patient']\n",
    "        if patient in patient_to_wsi_ids_relapse.keys():\n",
    "            patient_to_wsi_ids_relapse[patient].append(id)\n",
    "        else:\n",
    "            patient_to_wsi_ids_relapse[patient] = [id]\n",
    "if test_pct != 0:            \n",
    "    patients_relapse_train_and_valid, patients_relapse_test = train_test_split(list(patient_to_wsi_ids_relapse.keys()), \n",
    "                                                                               test_size=test_pct, \n",
    "                                                                               random_state=seed)\n",
    "    patients_relapse_train, patients_relapse_valid = train_test_split(patients_relapse_train_and_valid, \n",
    "                                                                      test_size=valid_pct, \n",
    "                                                                      random_state=seed)\n",
    "else:\n",
    "    patients_relapse_train, patients_relapse_valid = train_test_split(list(patient_to_wsi_ids_relapse.keys()), \n",
    "                                                                      test_size=valid_pct, \n",
    "                                                                      random_state=seed)\n",
    "    patients_relapse_test = []\n",
    "    \n",
    "    \n",
    "\n",
    "ids_relapse_train = flatten([patient_to_wsi_ids_relapse[pat] for pat in patients_relapse_train])\n",
    "ids_relapse_valid = flatten([patient_to_wsi_ids_relapse[pat] for pat in patients_relapse_valid])\n",
    "ids_relapse_test = flatten([patient_to_wsi_ids_relapse[pat] for pat in patients_relapse_test])\n",
    "\n",
    "tile_paths_relapse_all = [Path(f'{p.parts[-2]}/{p.parts[-1]}') for p in (TILES_RELAPSE.ls()) if p.suffix == '.png']\n",
    "tile_paths_relapse_train = [p for p in tile_paths_relapse_all if get_id_from_path(p) in ids_relapse_train]\n",
    "tile_paths_relapse_val = [p for p in tile_paths_relapse_all if get_id_from_path(p) in ids_relapse_valid]\n",
    "tile_paths_relapse_test = [p for p in tile_paths_relapse_all if get_id_from_path(p) in ids_relapse_test]\n",
    "\n",
    "\n",
    "###\n",
    "# NON RELAPSE\n",
    "###\n",
    "tile_paths_non_relapse_all = [Path(f'{p.parts[-2]}/{p.parts[-1]}') for p in (TILES_NON_RELAPSE.ls()) if p.suffix == '.png']\n",
    "\n",
    "ids_non_relapse_all = []\n",
    "for p in tqdm(tile_paths_non_relapse_all):\n",
    "    ids_non_relapse_all.append(get_id_from_path(p))\n",
    "ids_non_relapse_all = list(set(ids_non_relapse_all))\n",
    "\n",
    "if test_pct != 0:\n",
    "    ids_non_relapse_train_and_valid, ids_non_relapse_test = train_test_split(ids_non_relapse_all, \n",
    "                                                                             test_size=test_pct, \n",
    "                                                                             random_state=seed)\n",
    "    ids_non_relapse_train, ids_non_relapse_val = train_test_split(ids_non_relapse_train_and_valid, \n",
    "                                                                  test_size=valid_pct, \n",
    "                                                                  random_state=seed)\n",
    "else:\n",
    "    ids_non_relapse_train, ids_non_relapse_val = train_test_split(ids_non_relapse_all, \n",
    "                                                                  test_size=valid_pct, \n",
    "                                                                  random_state=seed)\n",
    "    ids_non_relapse_test = []\n",
    "    \n",
    "\n",
    "tile_paths_non_relapse_train = [p for p in tile_paths_non_relapse_all if get_id_from_path(p) in ids_non_relapse_train]\n",
    "tile_paths_non_relapse_val = [p for p in tile_paths_non_relapse_all if get_id_from_path(p) in ids_non_relapse_val]\n",
    "tile_paths_non_relapse_test = [p for p in tile_paths_non_relapse_all if get_id_from_path(p) in ids_non_relapse_test]\n",
    "\n",
    "###\n",
    "# COMBINE\n",
    "###\n",
    "tile_paths_train = tile_paths_non_relapse_train + tile_paths_relapse_train\n",
    "tile_paths_val = tile_paths_non_relapse_val + tile_paths_relapse_val\n",
    "tile_paths_test = tile_paths_non_relapse_test + tile_paths_relapse_test\n",
    "\n",
    "df_tile_paths_train_and_valid = pd.DataFrame((tile_paths_train+tile_paths_val), columns=['name'])\n",
    "\n",
    "print(f'seed: {seed}')\n",
    "print(len(tile_paths_train))\n",
    "print(len(tile_paths_val))\n",
    "print(len(tile_paths_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = get_transforms(flip_vert=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfms = ([RandTransform(tfm=TfmAffine (dihedral_affine), kwargs={}, p=1.0, resolved={}, do_run=True, is_random=True),\n",
    "#        RandTransform(tfm=TfmLighting (brightness), kwargs={'change': (0.475, 0.525)}, p=0.75, resolved={}, do_run=True, is_random=True),\n",
    "#        RandTransform(tfm=TfmLighting (contrast), kwargs={'scale': (0.95, 1.0526315789473684)}, p=0.75, resolved={}, do_run=True, is_random=True)],\n",
    "#        [])\n",
    "\n",
    "#def get_ex(): return open_image(str(TRAIN.ls()[0]))\n",
    "#\n",
    "#def plots_f(rows, cols, width, height, **kwargs):\n",
    "#    [get_ex().apply_tfms(tfms[0], **kwargs).show(ax=ax) for i,ax in enumerate(plt.subplots(\n",
    "#        rows,cols,figsize=(width,height))[1].flatten())]\n",
    "#\n",
    "#plots_f(2, 4, 12, 6, size=224)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datablock API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_func(path):\n",
    "    path = Path(path)\n",
    "    id = get_id_from_path(path)\n",
    "    if id in ids_non_relapse_all:\n",
    "        return [lbs2num['non_relapse']]\n",
    "    else:\n",
    "        return [lbs2num['relapse']]\n",
    "\n",
    "    \n",
    "def split_func(path):\n",
    "    path = Path(path)\n",
    "    return get_id_from_path(path) in (ids_non_relapse_val+ids_relapse_valid) \n",
    "\n",
    "#data = ImageList.from_folder(path=TRAIN, extensions=['.png'])\n",
    "data = ImageList.from_df(df_tile_paths_train_and_valid, path=PATH)\n",
    "data = data.split_by_valid_func(split_func)\n",
    "data = data.label_from_func(label_func)\n",
    "data = data.transform(tfms=tfms, size=sz)\n",
    "#data = data.add_test_folder(test_folder=TEST_EXPERIMENTING)\n",
    "if test_pct != 0:\n",
    "    data = data.add_test([PATH/p for p in tile_paths_test])\n",
    "data = data.databunch(bs=bs, num_workers=nw, path=PATH/'3-currently-training')\n",
    "data = data.normalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_frozen = 5\n",
    "epochs_unfrozen = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = resnext101_32x8d\n",
    "learner = cnn_learner(data=data, \n",
    "                     base_arch=arch, \n",
    "                     metrics=[accuracy_thresh], \n",
    "                     ps=dropout, \n",
    "                     pretrained=True, \n",
    "                     wd = wd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3-resnext101_32x8d-size512-bs6-epochs_head5-epochs_complete10-seed_23'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nameBase = f'{n}-{arch.__name__}-size{sz}-bs{bs}-epochs_head{epochs_frozen}-epochs_complete{epochs_unfrozen}-seed_{seed}'\n",
    "nameBase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.lr_find()\n",
    "learner.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy_thresh</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.460664</td>\n",
       "      <td>0.771280</td>\n",
       "      <td>0.639651</td>\n",
       "      <td>1:26:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.225278</td>\n",
       "      <td>0.795810</td>\n",
       "      <td>0.657021</td>\n",
       "      <td>1:15:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.209185</td>\n",
       "      <td>0.610823</td>\n",
       "      <td>0.720653</td>\n",
       "      <td>1:15:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.175567</td>\n",
       "      <td>0.566349</td>\n",
       "      <td>0.757131</td>\n",
       "      <td>1:15:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.153784</td>\n",
       "      <td>0.589237</td>\n",
       "      <td>0.744286</td>\n",
       "      <td>1:15:08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.fit_one_cycle(cyc_len=epochs_frozen, max_lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nameHead = f'{nameBase}-head'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save(nameHead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learner.load(nameHead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.lr_find()\n",
    "learner.recorder.plot(skip_start=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2 = 4e-7\n",
    "lr3 = 2e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.callbacks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='10', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      10.00% [1/10 1:50:04<16:30:38]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy_thresh</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.194363</td>\n",
       "      <td>0.508583</td>\n",
       "      <td>0.788490</td>\n",
       "      <td>1:49:53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='2287' class='' max='9842', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      23.24% [2287/9842 24:24<1:20:36 0.2412]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.fit_one_cycle(cyc_len=epochs_unfrozen, max_lr=slice(lr2, lr3), callbacks=[SaveModelCallback(learner, every='epoch', monitor='accuracy_thresh')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learner.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.recorder.plot_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nameComplete = f'{nameBase}-complete'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save(nameComplete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learner.load(nameComplete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### best learning schedules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction per case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(predicted_classes:list, all_classes:list):\n",
    "    for c in predicted_classes:\n",
    "        assert c in all_classes\n",
    "    n = len(all_classes)\n",
    "    res = np.zeros(n, int)\n",
    "    for i, c in enumerate(all_classes):\n",
    "        if c in predicted_classes:\n",
    "            res[i] = 1 \n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "def ensemble_predict(dict_arch_to_path_of_saved_model:typing.Dict[Callable, pathlib.Path], \n",
    "                     data:fastai.vision.data.ImageDataBunch,\n",
    "                     ds_type:fastai.basic_data.DatasetType,\n",
    "                     tta:bool, \n",
    "                     scale:float,\n",
    "                     beta:float):\n",
    "    \"\"\"\n",
    "    tta: Should test time augmentation be used?\n",
    "    scale: if tta is True -> scaling factor for tta\n",
    "    beta: if tta is True -> beta factor for tta\n",
    "    check this out for more infos: https://docs.fast.ai/basic_train.html#Test-time-augmentation\n",
    "    \"\"\"\n",
    "   \n",
    "    print(f'{str([a.__name__ for a in dict_arch_to_path_of_saved_model.keys()])}_sz{sz}_ensembled')\n",
    "    \n",
    "    predsList = []\n",
    "    for arch in dict_arch_to_path_of_saved_model.keys():\n",
    "        learner = cnn_learner(data=data, base_arch=arch, pretrained=False)\n",
    "        learner.load(dict_arch_to_path_of_saved_model[arch])\n",
    "        if tta is True:\n",
    "            preds = learner.TTA(beta=beta, scale=scale, ds_type=ds_type)\n",
    "        else:\n",
    "            preds = learner.get_preds(ds_type=ds_type)\n",
    "            \n",
    "        predsList.append(preds)\n",
    "    \n",
    "    preds_ensembled = predsList[0]\n",
    "    for n, _ in enumerate(predsList):\n",
    "        if n == 0:\n",
    "            continue\n",
    "        else:\n",
    "            preds_ensembled[0] = preds_ensembled[0] + predsList[n][0]\n",
    "    preds_ensembled[0] = preds_ensembled[0]/len(predsList)\n",
    "    \n",
    "    return preds_ensembled\n",
    "\n",
    "def from_preds_to_dict_path_to_preds(preds, \n",
    "                                     imageDataBunch:fastai.vision.ImageDataBunch, \n",
    "                                     ds_type:fastai.basic_data.DatasetType,\n",
    "                                     threshold:float):\n",
    "    \"\"\"\n",
    "    preds: What fastai.vision.learner.get_preds or fastai.vision.learner.TTA return.\n",
    "            two tensors: 1st: lists with raw predictions for each class of an image\n",
    "                         2nd: lists with y_true\n",
    "            form e.g. [tensor([[0.9672, 0.9211, 0.4560, 0.8185], \n",
    "                                [0.9498, 0.8600, 0.5852, 0.7206]]),\n",
    "                         tensor([[0., 0., 0., 1.],\n",
    "                                [0., 0., 1., 1.]])]\n",
    "                                \n",
    "    RETURN:\n",
    "        key:path, value:tuple (fastai.core.MultiCategory, tensor preds one hot encoded, tensor with pure preds) \n",
    "        e.g. (MultiCategory 0, tensor([1., 0., 0., 0.]), tensor([0.9952, 0.0015, 0.0021, 0.0029]))\n",
    "    path_to_pred = {}\n",
    "    \"\"\"\n",
    "    #key:path, value:tuple (fastai.core.MultiCategory, tensor preds one hot encoded, tensor with pure preds) \n",
    "    #e.g. (MultiCategory 0, tensor([1., 0., 0., 0.]), tensor([0.9952, 0.0015, 0.0021, 0.0029]))\n",
    "    path_to_pred = {}\n",
    "    d = None\n",
    "    if ds_type is DatasetType.Valid:\n",
    "        d = imageDataBunch.valid_ds\n",
    "    elif ds_type is DatasetType.Test:\n",
    "        d = imageDataBunch.test_ds\n",
    "    elif ds_type is DatasetType.Train:\n",
    "        d = imageDataBunch.train_ds\n",
    "    for path, pred in tqdm(zip(d.items, preds[0]), total = len(d.items)):\n",
    "        multi_c = None\n",
    "        pred_one_hot_encoded = (pred > threshold).float()\n",
    "        pred_raw = pred\n",
    "        path_to_pred[path] = multi_c, pred_one_hot_encoded, pred_raw\n",
    "        \n",
    "    return path_to_pred\n",
    "\n",
    "\n",
    "def get_class_occurence_per_id(learner:fastai.vision.learner=None,\n",
    "                               labelList:fastai.data_block.LabelList=None,\n",
    "                               dict_arch_to_path_of_saved_model:typing.Dict[Callable, pathlib.Path]=None,\n",
    "                               imageDataBunch:fastai.vision.data.ImageDataBunch=None,\n",
    "                               ds_type:fastai.basic_data.DatasetType=None,\n",
    "                               tta:bool=False,                                          \n",
    "                               threshold = 0.5,                              \n",
    "                               scale:float = 1.35,\n",
    "                               beta: float = 0.4):\n",
    "    \"\"\"\n",
    "    Option 1: Hand over a fastai.vision.learner and fastai.data_block.LabelList. No tta and no ensembling available\n",
    "                for this option.\n",
    "    Option 2: Hand over a fastai.vision.learner that was initalized with a fastai.vision.data.ImageDataBunch object.\n",
    "    Option 3: Hand over dict where the keys are functions to create a model (e.g. torchvision.models.resnet50)\n",
    "                and the values are paths to saved weights. Do this to use ensembling.\n",
    "    \n",
    "    Params:\n",
    "        threshold:  threshold to consider the predictions to be correct or not\n",
    "        scale: only needed when tta is True; scale value for fastai's fastai.basic_train.Learner.TTA function\n",
    "        beta: only needed when tta is True; beta value for fastai's fastai.basic_train.Learner.TTA function\n",
    "    \"\"\"\n",
    "    \n",
    "    if labelList is not None and ds_type is not None:\n",
    "        raise ValueError('One of dataset or ds_type must be None')\n",
    "    if labelList is not None and tta is True:\n",
    "        raise ValueError('TTA is not available for a custom LabelList')\n",
    "                \n",
    "    #key:path, value:tuple (fastai.core.MultiCategory, tensor preds one hot encoded, tensor with pure preds) \n",
    "    #e.g. (MultiCategory 0, tensor([1., 0., 0., 0.]), tensor([0.9952, 0.0015, 0.0021, 0.0029]))\n",
    "    path_to_pred = {}\n",
    "    \n",
    "    #Option 1\n",
    "    if learner is not None and labelList is not None:\n",
    "        for n, path in tqdm(enumerate(labelList.items), total=len(labelList.items)):\n",
    "            pred = learner.predict(labelList[n][0], thresh=threshold)\n",
    "            path_to_pred[path] = pred\n",
    "    \n",
    "    #Option 2\n",
    "    elif learner is not None and labelList is None and  not dict_arch_to_path_of_saved_model and imageDataBunch is None:\n",
    "        if tta is True:\n",
    "            preds = learner.TTA(beta=beta, scale=scale, ds_type=ds_type)\n",
    "        else:\n",
    "            preds = learner.get_preds(ds_type=ds_type)\n",
    "        path_to_pred = from_preds_to_dict_path_to_preds(preds, learner.data, ds_type, threshold)\n",
    "                \n",
    "    #Option 3\n",
    "    elif dict_arch_to_path_of_saved_model and imageDataBunch is not None:\n",
    "        preds = ensemble_predict(dict_arch_to_path_of_saved_model, imageDataBunch, ds_type, tta, scale, beta)\n",
    "        path_to_pred = from_preds_to_dict_path_to_preds(preds, imageDataBunch, ds_type, threshold)                \n",
    "               \n",
    "    #key: id of a case; value: list with this syntax  \n",
    "    #[<number of tiles>, \n",
    "    #[<number of occurence of class1 over all tiles per id>, \n",
    "    #<number of occurence of class2 over all tiles per id>, ..., \n",
    "    #<number of occurence of classN over all tiles per id>],\n",
    "    #y_true]\n",
    "    class_occurence_per_id = {}\n",
    "    \n",
    "    for path, pred in path_to_pred.items():   \n",
    "        id = get_id_from_path(path)\n",
    "        if id in class_occurence_per_id:\n",
    "            v = class_occurence_per_id[id]\n",
    "            v[0] = v[0] + 1\n",
    "            v[1] = v[1] + pred[1]\n",
    "            class_occurence_per_id[id] = v\n",
    "        else:\n",
    "            class_occurence_per_id[id] = [1, pred[1], one_hot_encode(label_func(path), lbs2num.values())]\n",
    "            \n",
    "    return class_occurence_per_id\n",
    "\n",
    "\n",
    "def get_preds_threshold_per_id(thresholds_per_class:list, class_occurence_per_id:dict):\n",
    "    #key: id of a case; \n",
    "    #value: list with this syntax  \n",
    "    #[y_pred_th e.g. [True,False,False,False], \n",
    "    #y_true e.g. [1,0,0,0]]\n",
    "    result = {}\n",
    "    for k in class_occurence_per_id.keys():\n",
    "        y_pred_th = []\n",
    "        for n, i in enumerate(class_occurence_per_id[k][1]):\n",
    "            i = int(i)\n",
    "            y_pred_th.append(i/class_occurence_per_id[k][0] > thresholds_per_class[n])\n",
    "    \n",
    "        result[k] = [y_pred_th, class_occurence_per_id[k][2]]\n",
    "    return result\n",
    "\n",
    "def get_accuracy_over_all_ids(number_of_ids, preds_threshold_per_id:dict, per_class:bool = True, number_of_classes = len(lbs2num)):\n",
    "    if per_class is True:\n",
    "        correctly_predicted = np.zeros(number_of_classes, dtype=np.int)\n",
    "    else:\n",
    "        correctly_predicted = 0\n",
    "    for k in preds_threshold_per_id.keys():\n",
    "        pred = preds_threshold_per_id[k][0]\n",
    "        true = preds_threshold_per_id[k][1]\n",
    "        for i in range(number_of_classes):\n",
    "            if true[i] == pred[i]:\n",
    "                if per_class is True:\n",
    "                    correctly_predicted[i] = correctly_predicted[i] + 1\n",
    "                else:\n",
    "                    correctly_predicted = correctly_predicted + 1\n",
    "    if per_class is True:                    \n",
    "        correctly_predicted_percentage = {}\n",
    "        for lb, num in zip(lbs2num.keys(), correctly_predicted):\n",
    "            correctly_predicted_percentage[lb] = num/number_of_ids\n",
    "    if per_class is False:\n",
    "        correctly_predicted_percentage = correctly_predicted/number_of_ids\n",
    "\n",
    "    return correctly_predicted_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#arches = {resnext101_32x8d:Path(MODEL_PATH/'6-resnext101_32x8d-size512-bs8-seed_73/bestmodel_15'),\n",
    "         # se_resnext101_32x4d:MODEL_PATH/'11-se_resnext101_32x4d-size512-bs10-epochs_head5-epochs_complete5-seed_73/11-se_resnext101_32x4d-size512-bs8-epochs_head5-epochs_complete5-seed_73-complete'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ths = [0.5,0.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copi_val = get_class_occurence_per_id(dict_arch_to_path_of_saved_model=arches,\n",
    "#                                      imageDataBunch=data,\n",
    "#                                      ds_type=DatasetType.Valid)\n",
    "copi_val = get_class_occurence_per_id(learner=learner, ds_type=DatasetType.Valid)\n",
    "preds_th_val = get_preds_threshold_per_id(ths, copi_val)\n",
    "accuracy_per_class_val = get_accuracy_over_all_ids(len(preds_th_val), preds_th_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_per_class_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copi_test = get_class_occurence_per_id(dict_arch_to_path_of_saved_model=arches,\n",
    "#                                      imageDataBunch=data,\n",
    "#                                      ds_type=DatasetType.Test)\n",
    "copi_test = get_class_occurence_per_id(learner=learner, ds_type=DatasetType.Test)\n",
    "preds_th_test = get_preds_threshold_per_id(ths, copi_test)\n",
    "accuracy_per_class_test = get_accuracy_over_all_ids(len(preds_th_test), preds_th_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_per_class_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def custom_confusion_matrix(self, slice_size:int=1):\n",
    "        \"Confusion matrix as an `np.ndarray`.\"\n",
    "        x=torch.arange(0,self.data.c)\n",
    "        if slice_size is None: cm = ((self.pred_class==x[:,None]) & (self.y_true==x[:,None,None])).sum(2)\n",
    "        else:\n",
    "            cm = torch.zeros(self.data.c, self.data.c, dtype=x.dtype)\n",
    "            for i in range(0, self.y_true.shape[0], slice_size):\n",
    "                #cm_slice = ((self.pred_class[i:i+slice_size]==x[:,None])\n",
    "                            #& (self.y_true[i:i+slice_size]==x[:,None,None])).sum(2)\n",
    "                cm_slice = ((self.pred_class[i:i+slice_size]==x[:,None])\n",
    "                            & (self.y_true[i:i+slice_size]==(x[:,None,None]).float())).sum(2)\n",
    "                torch.add(cm, cm_slice, out=cm)\n",
    "        return to_np(cm)\n",
    "    \n",
    "fastai.train.ClassificationInterpretation.confusion_matrix = custom_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "interp.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "interp.plot_top_losses(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Validation Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "preds,y=learner.TTA(ds_type=DatasetType.Valid, scale=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## AUC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pred_score_tta_1=auc_score_1(preds,y)\n",
    "pred_score_tta_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pred_score_tta_2=auc_score_2(preds,y)\n",
    "pred_score_tta_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## ROC curve and AUC on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds, roc_auc = roc_curve_custom(preds, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "plt.xlim([-0.01, 1.0])\n",
    "plt.ylim([0.0, 1.01])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Finding threshold on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import scipy.optimize as opt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pred = preds[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pred_tensor = pred\n",
    "y_tensor = y\n",
    "\n",
    "pred = np.asarray(pred)\n",
    "y = np.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def sigmoid_np(x):\n",
    "    return 1.0/(1.0 + np.exp(-x))\n",
    "\n",
    "def F1_soft(preds,targs,th=0.,d=25.0):\n",
    "    preds = sigmoid_np(d*(preds - th))\n",
    "    targs = targs.astype(np.float)\n",
    "    score = 2.0*(preds*targs).sum(axis=0)/((preds+targs).sum(axis=0) + 1e-6)\n",
    "    return score\n",
    "\n",
    "def fit_val(x,y):\n",
    "    params = np.zeros(1)\n",
    "    wd = 1e-5\n",
    "    error = lambda p: np.concatenate((F1_soft(x,y,p) - 1.0,\n",
    "                                      wd*p), axis=None)\n",
    "    p, success = opt.leastsq(error, params)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "th = fit_val(pred, y)\n",
    "print('Thresholds: ',th)\n",
    "print('F1 macro: ', sklearn.metrics.f1_score(y, pred>th, average='macro'))\n",
    "print('F1 macro (th = 0.0): ', sklearn.metrics.f1_score(y, pred>0.0, average='macro'))\n",
    "print('F1 micro: ', sklearn.metrics.f1_score(y, pred>th, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "th, score, cv = 0,0,10\n",
    "for i in range(cv):\n",
    "    xt,xv,yt,yv = train_test_split(pred,y,test_size=0.5,random_state=i)\n",
    "    th_i = fit_val(xt,yt)\n",
    "    th += th_i\n",
    "    score +=  sklearn.metrics.f1_score(yv, xv>th_i, average='macro')\n",
    "th/=cv\n",
    "score/=cv\n",
    "print('Thresholds: ',th)\n",
    "print('F1 macro avr:',score)\n",
    "print('F1 macro: ', sklearn.metrics.f1_score(y, pred>th, average='macro'))\n",
    "print('F1 micro: ', sklearn.metrics.f1_score(y, pred>th, average='micro'))\n",
    "\n",
    "\n",
    "print('Fractions: ',(pred > th).mean(axis=0))\n",
    "print('Fractions (true): ',(y > 0.5).mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "f1 =  sklearn.metrics.f1_score(y, pred>th, average=None)\n",
    "bins = np.linspace(pred[:].min(), pred[:].max(), 50)\n",
    "plt.hist(pred[y[:] == 0][:], bins, alpha=0.5, log=True, label='false')\n",
    "plt.hist(pred[y[:] == 1][:], bins, alpha=0.5, log=True, label='true')\n",
    "plt.legend(loc='upper right')\n",
    "plt.axvline(x=th[0], color='k', linestyle='--')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLM Py3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "293px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "#%matplotlib notebook\n",
    "import sys\n",
    "###\n",
    "#!pip install openslide-python\n",
    "#https://github.com/deroneriksson/python-wsi-preprocessing/\n",
    "###\n",
    "sys.path.append('../python-wsi-preprocessing/')\n",
    "from deephistopath.wsi import slide, filter, tiles, util\n",
    "\n",
    "import fastai\n",
    "from fastai.vision import *\n",
    "from fastai.core import parallel\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "from functools import partial, update_wrapper\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from enum import Enum\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import openslide\n",
    "from openslide.lowlevel import *\n",
    "Image.MAX_IMAGE_PIXELS = 10000000000\n",
    "\n",
    "PATH = Path('/home/Deep_Learner/private/network/datasets/Hypophysenadenome/')\n",
    "FONT_PATH=PATH/'1984-Happines-Regular.ttf'\n",
    "ROIS_CORTICOTROP = PATH/'rois_corticotrop'\n",
    "ROIS_CORTICOTROP_FILTERED = PATH/'rois_corticotrop_filtered'\n",
    "ROIS_GONADOTROP = PATH/'rois_gonadotrop'\n",
    "ROIS_GONADOTROP_FILTERED = PATH/'rois_gonadotrop_filtered'\n",
    "TILES_CORTICOTROP = PATH/'tiles_corticotrop'\n",
    "TILES_GONADOTROP = PATH/'tiles_gonadotrop'\n",
    "\n",
    "ROIS_EXPERIMENTING = PATH/'rois_experimenting'\n",
    "ROIS_EXPERIMENTING_FILTERED = PATH/'rois_experimenting_filtered'\n",
    "TILES_EXPERIMENTING = PATH/'tiles_experimenting'\n",
    "\n",
    "PATH_RELAPSE = Path('/home/Deep_Learner/private/network/datasets/Hypophysenadenome-Rezidive/')\n",
    "RELAPSE_WSIS_EXPERIMENTING = PATH_RELAPSE/'wsis_experimenting'\n",
    "RELAPSE_IMAGES_EXPERIMENTING = PATH_RELAPSE/'imgs_experimenting'\n",
    "RELAPSE_IMAGES_FILTERED_EXPERIMENTING = PATH_RELAPSE/'imgs_filtered_experimenting'\n",
    "RELAPSE_TILES_EXPERIMENTING = PATH_RELAPSE/'tiles_experimenting'\n",
    "\n",
    "NONE_RELAPSE_WSIS = PATH_RELAPSE/'wsis_non_relapse'\n",
    "NONE_RELAPSE_IMAGES = PATH_RELAPSE/'imgs_non_relapse'\n",
    "NONE_RELAPSE_IMAGES_FILTERED = PATH_RELAPSE/'imgs_filtered_non_relapse'\n",
    "NONE_RELAPSE_TILES = PATH_RELAPSE/'tiles_non_relapse'\n",
    "\n",
    "RELAPSE_WSIS = PATH_RELAPSE/'wsis_relapse'\n",
    "RELAPSE_IMAGES = PATH_RELAPSE/'imgs_relapse'\n",
    "RELAPSE_IMAGES_FILTERED = PATH_RELAPSE/'imgs_filtered_relapse'\n",
    "RELAPSE_TILES = PATH_RELAPSE/'tiles_relapse'\n",
    "\n",
    "\n",
    "def show(np):\n",
    "    return util.np_to_pil(np)\n",
    "\n",
    "Path.ls = lambda x: [p for p in list(x.iterdir()) if '.ipynb_checkpoints' not in p.name]\n",
    "\n",
    "def show_multiple_images(path, rows = 3, figsize=(128, 64)):\n",
    "    imgs = [open_image(p) for p in path.ls()]\n",
    "    show_all(imgs=imgs, r=rows, figsize=figsize)\n",
    "    \n",
    "def show_multiple_images_big(path:pathlib.Path):\n",
    "    for p in path.ls():\n",
    "        plt.imshow(mpimg.imread(str(p)))\n",
    "        plt.show()\n",
    "        \n",
    "class AdenomaType(Enum):\n",
    "    experimenting = 0\n",
    "    corticotrop = 1\n",
    "    gonadotrop = 2\n",
    "    relapse_experimenting = 3\n",
    "    relapse = 4\n",
    "    non_relapse = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adenomaType = AdenomaType.relapse\n",
    "\n",
    "if adenomaType == AdenomaType.gonadotrop:\n",
    "    rois_filtered_path = ROIS_GONADOTROP_FILTERED\n",
    "    rois_path = ROIS_GONADOTROP\n",
    "    tiles_path = TILES_GONADOTROP\n",
    "    \n",
    "if adenomaType == AdenomaType.corticotrop:\n",
    "    rois_filtered_path = ROIS_CORTICOTROP_FILTERED\n",
    "    rois_path = ROIS_CORTICOTROP\n",
    "    tiles_path = TILES_CORTICOTROP\n",
    "    \n",
    "if adenomaType == AdenomaType.experimenting:\n",
    "    wsi_path = ROIS_EXPERIMENTING\n",
    "    rois_filtered_path = ROIS_EXPERIMENTING_FILTERED\n",
    "    rois_path = ROIS_EXPERIMENTING\n",
    "    tiles_path = TILES_EXPERIMENTING\n",
    "    \n",
    "if adenomaType == AdenomaType.relapse_experimenting:\n",
    "    wsi_path = RELAPSE_WSIS_EXPERIMENTING\n",
    "    rois_filtered_path = RELAPSE_IMAGES_FILTERED_EXPERIMENTING\n",
    "    rois_path = RELAPSE_IMAGES_EXPERIMENTING\n",
    "    tiles_path = RELAPSE_TILES_EXPERIMENTING\n",
    "    \n",
    "if adenomaType == AdenomaType.relapse:\n",
    "    wsi_path = RELAPSE_WSIS\n",
    "    rois_path = RELAPSE_IMAGES\n",
    "    rois_filtered_path = RELAPSE_IMAGES_FILTERED\n",
    "    tiles_path = RELAPSE_TILES  \n",
    "    \n",
    "if adenomaType == AdenomaType.non_relapse:\n",
    "    wsi_path = NONE_RELAPSE_WSIS\n",
    "    rois_path = NONE_RELAPSE_IMAGES\n",
    "    rois_filtered_path = NONE_RELAPSE_IMAGES_FILTERED\n",
    "    tiles_path = NONE_RELAPSE_TILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rois_path.mkdir(exist_ok=True)\n",
    "rois_filtered_path.mkdir(exist_ok=True)\n",
    "tiles_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overwrite parts of wsi lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slide.SCALE_FACTOR = 2\n",
    "\n",
    "\n",
    "slide.BASE_DIR = PATH/'data'\n",
    "slide.SRC_TRAIN_EXT = \"ndpi\"\n",
    "tiles.SUMMARY_TITLE_FONT_PATH = str(FONT_PATH)\n",
    "tiles.FONT_PATH = str(FONT_PATH)\n",
    "tiles.DISPLAY_TILE_SUMMARY_LABELS = True\n",
    "tiles.LABEL_ALL_TILES_IN_TOP_TILE_SUMMARY = True\n",
    "tiles.BORDER_ALL_TILES_IN_TOP_TILE_SUMMARY = True\n",
    "tiles.TISSUE_LOW_THRESH = 20\n",
    "\n",
    "tiles.ROW_TILE_SIZE = 1024\n",
    "tiles.COL_TILE_SIZE = 1024\n",
    "\n",
    "##################################################################################################################\n",
    "\n",
    "slide.open_slide = slide.open_image\n",
    "\n",
    "##################################################################################################################\n",
    "\n",
    "def get_image_path(folder_path, slide_num):\n",
    "    return folder_path.ls()[slide_num]\n",
    "\n",
    "slide.get_filter_image_result = partial(get_image_path, rois_filtered_path)\n",
    "slide.get_training_image_path = partial(get_image_path, rois_path)\n",
    "slide.get_training_slide_path = partial(get_image_path, wsi_path)\n",
    "\n",
    "##################################################################################################################\n",
    "\n",
    "def parse_dimensions_from_image_filename(img_path):\n",
    "    shape = slide.open_image_np(img_path).shape\n",
    "    return shape[1], shape[0], shape[1], shape[0]\n",
    "\n",
    "slide.parse_dimensions_from_image_filename = parse_dimensions_from_image_filename\n",
    "\n",
    "##################################################################################################################\n",
    "\n",
    "def tile_to_pil_tile(tile):\n",
    "  \"\"\"\n",
    "  Convert tile information into the corresponding tile as a PIL image read from the whole-slide image file.\n",
    "\n",
    "  Args:\n",
    "    tile: Tile object.\n",
    "\n",
    "  Return:\n",
    "    Tile as a PIL image.\n",
    "  \"\"\"\n",
    "  t = tile\n",
    "  filepath = slide.get_training_image_path(t.slide_num)\n",
    "  img = slide.open_image_np(filepath)\n",
    "  #x, y = t.o_c_s, t.o_r_s\n",
    "  #w, h = t.o_c_e - t.o_c_s, t.o_r_e - t.o_r_s\n",
    "  tile = img[int(t.o_r_s/slide.SCALE_FACTOR):int(t.o_r_e/slide.SCALE_FACTOR), int(t.o_c_s/slide.SCALE_FACTOR):int(t.o_c_e/slide.SCALE_FACTOR),:]\n",
    "  tile_pil = util.np_to_pil(tile)\n",
    "  return tile_pil\n",
    "\n",
    "tiles.tile_to_pil_tile = tile_to_pil_tile\n",
    "\n",
    "##################################################################################################################\n",
    "def get_tile_image_path(tile):\n",
    "  \"\"\"\n",
    "  Obtain tile image path based on tile information such as row, column, row pixel position, column pixel position,\n",
    "  pixel width, and pixel height.\n",
    "\n",
    "  Args:\n",
    "    tile: Tile object.\n",
    "\n",
    "  Returns:\n",
    "    Path to image tile.\n",
    "  \"\"\"\n",
    "  t = tile\n",
    "  roi_name = slide.get_training_image_path(t.slide_num).stem\n",
    "  tile_path = os.path.join(PATH, tiles_path,\n",
    "                           roi_name + \"-\" + 'tile' + \"-r%d-c%d-x%d-y%d-w%d-h%d\" % (\n",
    "                             t.r, t.c, t.o_c_s, t.o_r_s, t.o_c_e - t.o_c_s, t.o_r_e - t.o_r_s) + \".\" + 'png')\n",
    "  return tile_path\n",
    "\n",
    "slide.get_tile_image_path = get_tile_image_path\n",
    "\n",
    "##################################################################################################################\n",
    "\n",
    "def top_tiles(self):\n",
    "    \"\"\"\n",
    "    Retrieve the top-scoring tiles.\n",
    "\n",
    "    Returns:\n",
    "       List of the top-scoring tiles.\n",
    "    \"\"\"\n",
    "    sorted_tiles = self.tiles_by_score()\n",
    "    top_tiles = [tile for tile in sorted_tiles\n",
    "                 if check_tile(tile)]\n",
    "    print(f'Number of top tiles/all tiles: {len(top_tiles)}/{len(sorted_tiles)}')\n",
    "    return top_tiles\n",
    "\n",
    "def check_tile(tile):\n",
    "    width = tile.o_c_e - tile.o_c_s\n",
    "    height = tile.o_r_e - tile.o_r_s\n",
    "    return tile.score > 0.55 and width >= 0.7*tiles.COL_TILE_SIZE and height >= 0.7*tiles.ROW_TILE_SIZE\n",
    "\n",
    "\n",
    "tiles.TileSummary.top_tiles = top_tiles\n",
    "\n",
    "##################################################################################################################\n",
    "from deephistopath.wsi.tiles import (hsv_saturation_and_value_factor, \n",
    "                                     hsv_purple_pink_factor, \n",
    "                                     tissue_quantity_factor, \n",
    "                                     tissue_quantity)\n",
    "\n",
    "def score_tile(np_tile, tissue_percent, slide_num, row, col):\n",
    "  \"\"\"\n",
    "  Score tile based on tissue percentage, color factor, saturation/value factor, and tissue quantity factor.\n",
    "\n",
    "  Args:\n",
    "    np_tile: Tile as NumPy array.\n",
    "    tissue_percent: The percentage of the tile judged to be tissue.\n",
    "    slide_num: Slide number.\n",
    "    row: Tile row.\n",
    "    col: Tile column.\n",
    "\n",
    "  Returns tuple consisting of score, color factor, saturation/value factor, and tissue quantity factor.\n",
    "  \"\"\"\n",
    "  color_factor = hsv_purple_pink_factor(np_tile)\n",
    "  s_and_v_factor = hsv_saturation_and_value_factor(np_tile)\n",
    "  amount = tissue_quantity(tissue_percent)\n",
    "  quantity_factor = tissue_quantity_factor(amount)\n",
    "  combined_factor = color_factor * s_and_v_factor\n",
    "  score = tissue_percent * combined_factor / 1000.0\n",
    "  # scale score to between 0 and 1\n",
    "  score = 1.0 - (10.0 / (10.0 + score))\n",
    "  #print(f'tp: {tissue_percent}')\n",
    "  #print(f'cf: {combined_factor}')\n",
    "  #print(f'score: {score}')  \n",
    "  return score, color_factor, s_and_v_factor, quantity_factor\n",
    "\n",
    "tiles.score_tile = score_tile\n",
    "#tiles.score_tile = tiles.score_tile\n",
    "#############################################################################################################\n",
    "\n",
    "def _load_image(buf, size):\n",
    "        '''buf must be a buffer.'''\n",
    "\n",
    "        # Load entire buffer at once if possible\n",
    "        MAX_PIXELS_PER_LOAD = (1 << 29) - 1\n",
    "        # Otherwise, use chunks smaller than the maximum to reduce memory\n",
    "        # requirements\n",
    "        PIXELS_PER_LOAD = 1 << 26\n",
    "\n",
    "        def do_load(buf, size):\n",
    "            '''buf can be a string, but should be a ctypes buffer to avoid an\n",
    "            extra copy in the caller.'''\n",
    "            # First reorder the bytes in a pixel from native-endian aRGB to\n",
    "            # big-endian RGBa to work around limitations in RGBa loader\n",
    "            rawmode = (sys.byteorder == 'little') and 'BGRA' or 'ARGB'\n",
    "            buf = PIL.Image.frombuffer('RGBA', size, buf, 'raw', rawmode, 0, 1)\n",
    "            # Image.tobytes() is named tostring() in Pillow 1.x and PIL\n",
    "            buf = (getattr(buf, 'tobytes', None) or buf.tostring)()\n",
    "            # Now load the image as RGBA, undoing premultiplication\n",
    "            return PIL.Image.frombuffer('RGBA', size, buf, 'raw', 'RGBa', 0, 1)\n",
    "\n",
    "        # Fast path for small buffers\n",
    "        w, h = size\n",
    "        if w * h <= MAX_PIXELS_PER_LOAD:\n",
    "            return do_load(buf, size)\n",
    "\n",
    "        # Load in chunks to avoid OverflowError in PIL.Image.frombuffer()\n",
    "        # https://github.com/python-pillow/Pillow/issues/1475\n",
    "        if w > PIXELS_PER_LOAD:\n",
    "            # We could support this, but it seems like overkill\n",
    "            raise ValueError('Width %d is too large (maximum %d)' %\n",
    "                    (w, PIXELS_PER_LOAD))\n",
    "        rows_per_load = PIXELS_PER_LOAD // w\n",
    "        img = PIL.Image.new('RGBA', (w, h))\n",
    "        for y in range(0, h, rows_per_load):\n",
    "            rows = min(h - y, rows_per_load)\n",
    "            if sys.version[0] == '2':\n",
    "                chunk = buffer(buf, 4 * y * w, 4 * rows * w)\n",
    "            else:\n",
    "                # PIL.Image.frombuffer() won't take a memoryview or\n",
    "                # bytearray, so we can't avoid copying\n",
    "                chunk = memoryview(buf)[y * w:(y + rows) * w].tobytes()\n",
    "            img.paste(do_load(chunk, (w, rows)), (0, y))\n",
    "        return img\n",
    "\n",
    "openslide.lowlevel._load_image = _load_image\n",
    "\n",
    "\n",
    "def slide_to_scaled_pil_image(slide_filepath):\n",
    "  \"\"\"\n",
    "  Convert a WSI training slide to a scaled-down PIL image.\n",
    "\n",
    "  Args:\n",
    "    slide_number: The slide number.\n",
    "\n",
    "  Returns:\n",
    "    Tuple consisting of scaled-down PIL image, original width, original height, new width, and new height.\n",
    "  \"\"\"\n",
    "  sl = openslide.open_slide(str(slide_filepath))\n",
    "\n",
    "  large_w, large_h = sl.dimensions\n",
    "  new_w = math.floor(large_w / slide.SCALE_FACTOR)\n",
    "  new_h = math.floor(large_h / slide.SCALE_FACTOR)\n",
    "  level = sl.get_best_level_for_downsample(slide.SCALE_FACTOR)\n",
    "  whole_slide_image = sl.read_region((0, 0), level, sl.level_dimensions[level])\n",
    "  whole_slide_image = whole_slide_image.convert(\"RGB\")\n",
    "  img = whole_slide_image.resize((new_w, new_h), PIL.Image.BILINEAR)\n",
    "  return img, large_w, large_h, new_w, new_h\n",
    "\n",
    "slide.slide_to_scaled_pil_image = slide_to_scaled_pil_image\n",
    "\n",
    "\n",
    "def training_slide_to_image(slide_filepath):\n",
    "  \"\"\"\n",
    "  Convert a WSI training slide to a saved scaled-down image in a format such as jpg or png.\n",
    "\n",
    "  Args:\n",
    "    slide_number: The slide number.\n",
    "  \"\"\"\n",
    "  img, large_w, large_h, new_w, new_h = slide_to_scaled_pil_image(slide_filepath)\n",
    "  img_path = f'{rois_path}/{slide_filepath.stem}-scale_factor_{slide.SCALE_FACTOR}.png'\n",
    "  print(\"Saving image to: \" + img_path)\n",
    "  img.save(img_path)\n",
    "\n",
    "slide.training_slide_to_image = training_slide_to_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Convert WSIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#def convert_wsi_to_png(path:pathlib.Path, index:int):\n",
    "#    #try:\n",
    "#        slide.training_slide_to_image(path)\n",
    "#        print(f'Saved {path.stem}.png')\n",
    "#    #except:\n",
    "#        #print(path)\n",
    "#        \n",
    "#fastai.core.parallel(convert_wsi_to_png, wsi_path.ls(), max_workers=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for p in tqdm(wsi_path.ls()):\n",
    "    for b in rois_path.ls():\n",
    "        if p.stem == b.stem:\n",
    "            break\n",
    "    else:\n",
    "        slide.training_slide_to_image(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# for 'normal' img formats like .png\n",
    "##\n",
    "\n",
    "def filter_roi(img_path:pathlib.Path, index:int):\n",
    "    if img_path.suffix == '.png':\n",
    "        try:\n",
    "            img_pil = slide.open_image(img_path)\n",
    "            img_np = util.pil_to_np_rgb(img_pil)\n",
    "            grayscale_np = filter.filter_rgb_to_grayscale(img_np)\n",
    "            complement_np = filter.filter_complement(grayscale_np)\n",
    "            otsu_np = filter.filter_otsu_threshold(complement_np).astype(np.bool)\n",
    "            filtered_img_np = util.mask_rgb(img_np, otsu_np)\n",
    "            filtered_img_pil = util.np_to_pil(filtered_img_np)\n",
    "            #filtered_path = rois_filtered_path/f'{img_path.stem}-filtered{img_path.suffix}'\n",
    "            filtered_path = rois_filtered_path/f'{img_path.stem}{img_path.suffix}'\n",
    "            try:\n",
    "                filtered_img_pil = util.np_to_pil(filtered_img_np)\n",
    "                filtered_img_pil.save(filtered_path)\n",
    "            except ValueError as e:\n",
    "                #cv2 expects the array to have bgr as channel order\n",
    "                bgr = filtered_img_np[...,[2,1,0]]\n",
    "                cv2.imwrite(str(filtered_path), bgr)\n",
    "        except:\n",
    "            print(img_path)\n",
    "###\n",
    "# use this line instead of the following for loop to do the filtering in parallel with mutiple threads\n",
    "###\n",
    "#parallel(filter_roi, rois_path.ls(), max_workers=25)\n",
    "\n",
    "failed = []\n",
    "for p in tqdm(rois_path.ls()):\n",
    "    try:\n",
    "        filter_roi(p,0)\n",
    "    except:\n",
    "        failed.append(p)\n",
    "    \n",
    "print(failed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Fix for PIL Value Error\n",
    "PIL raises an ValueEerror, when using Image.fromarray() with very big numpy arrays.\n",
    "In this case use cv2. Beware that you have to switch rgb to bgr in numpy array before saving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pa = Path('/home/Deep_Learner/private/network/datasets/Hypophysenadenome-Rezidive/imgs_relapse/495-09-III-HE-scale_factor_2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "img_pil = slide.open_image(pa)\n",
    "img_np = util.pil_to_np_rgb(img_pil)\n",
    "grayscale_np = filter.filter_rgb_to_grayscale(img_np)\n",
    "complement_np = filter.filter_complement(grayscale_np)\n",
    "otsu_np = filter.filter_otsu_threshold(complement_np).astype(np.bool)\n",
    "filtered_img_np = util.mask_rgb(img_np, otsu_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(filtered_img_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "filtered_path = rois_filtered_path/f'{pa.stem}{pa.suffix}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    filtered_img_pil = util.np_to_pil(filtered_img_np)\n",
    "    filtered_img_pil.save(filtered_path)\n",
    "except ValueError as e:\n",
    "    bgr = filtered_img_np[...,[2,1,0]]\n",
    "    cv2.imwrite(str(filtered_path), bgr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ü = filtered_img_np[10000:12000,3500:5000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(ü)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "path_pil = rois_filtered_path/f'{pa.stem}-pil-{pa.suffix}'\n",
    "filtered_img_pil = util.np_to_pil(ü)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "path_cv = rois_filtered_path/f'{pa.stem}-cv2-{pa.suffix}'\n",
    "bgr = ü[...,[2,1,0]]\n",
    "cv2.imwrite(str(path_cv), bgr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "open_image(path_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "open_image(path_pil)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create tiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multi process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles.multiprocess_filtered_images_to_tiles(display=False, \n",
    "                                            save_summary=False, \n",
    "                                            save_data=False, \n",
    "                                            save_top_tiles=True,\n",
    "                                            html=False, \n",
    "                                            image_num_list=list(range(0, len(rois_filtered_path.ls()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tiles_path.ls())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_multiple_images_big(tiles_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!rm -r {rois_filtered_path/'*'}\n",
    "#!rm -r {tiles_path/'*'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## single process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#!rm -r {tiles_path/'*'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "failed = []\n",
    "for n, p in tqdm(enumerate(rois_filtered_path.ls()[:1]), total=len(rois_filtered_path.ls())-1):\n",
    "    if p.suffix == '.png':\n",
    "        try:\n",
    "            print(p)\n",
    "            tiles.summary_and_tiles(n, display=False, save_summary=False, save_data=False, save_top_tiles=True)\n",
    "        except:\n",
    "            failed.append(p)\n",
    "            \n",
    "print(failed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import PIL\n",
    "p = '/home/Deep_Learner/work/network/datasets/Hypophysenadenome/rois_corticotrop/1000-13-III-HE-ROI_1-ACTH.png'\n",
    "\n",
    "img_pil = slide.open_image(p)\n",
    "img_np = util.pil_to_np_rgb(img_pil)\n",
    "grayscale_np = filter.filter_rgb_to_grayscale(img_np)\n",
    "complement_np = filter.filter_complement(grayscale_np)\n",
    "otsu_np = filter.filter_otsu_threshold(complement_np).astype(np.bool)\n",
    "filtered_img_np = util.mask_rgb(img_np, otsu_np)\n",
    "\n",
    "plt.imshow(filtered_img_np)\n",
    "\n",
    "tiles = []\n",
    "sz = 512\n",
    "for i in range(int(filtered_img_np.shape[0]/sz)):\n",
    "    for j in range(int(filtered_img_np.shape[1]/sz)):\n",
    "         tiles.append(filtered_img_np[i*sz:(i+1)*sz,j*sz:(j+1)*sz])\n",
    "        \n",
    "\n",
    "for t in tiles:\n",
    "    print(t.shape)\n",
    "    nz = np.count_nonzero(t)// 3\n",
    "    print(f'tissue percentage:{(nz/(t.shape[0]*t.shape[1]))*100}')\n",
    "    plt.imshow(t)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLM Py3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "300px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
